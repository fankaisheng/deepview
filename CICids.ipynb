{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepview import DeepView\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "# ---------------------------\n",
    "import demo_utils as demo\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch_dct\n",
    "from deepview.embeddings import init_umap, init_inv_umap\n",
    "from deepview.fisher_metric import calculate_fisher\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 流量前期处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNN_NIDS(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=59, out_features=4096, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Linear(in_features=4096, out_features=512, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (4): Linear(in_features=512, out_features=9, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DNN_NIDS(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN_NIDS, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(59, 4096),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(4096, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 9)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model=DNN_NIDS()\n",
    "model.load_state_dict(torch.load('CIC_model2.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NIDS_dataset(Dataset):\n",
    "    def __init__(self, file):\n",
    "        df = pd.read_csv(file, index_col=False)\n",
    "        self.items = np.array(df.iloc[:,:-1])\n",
    "        self.items = (self.items - np.mean(self.items, axis=1, keepdims=True)) / (\n",
    "                    np.std(self.items, axis=1, keepdims=True) + 0.00001)\n",
    "        self.label = np.array(df.iloc[:,-1])\n",
    "\n",
    "    def __len__(self):\n",
    "        # print('item的长度是',len(self.items))\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # print(self.items[idx,:],self.label[idx])\n",
    "        return self.items[idx, :], self.label[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BENIGN': [], 'PortScan': [], 'Web': [], 'SSH-Patator': [], 'FTP-Patator': [], 'Bot': [], 'DoS Hulk': [], 'DoS GoldenEye': [], 'DDoS': []}\n",
      "{0: 'BENIGN', 1: 'PortScan', 2: 'Web', 3: 'SSH-Patator', 4: 'FTP-Patator', 5: 'Bot', 6: 'DoS Hulk', 7: 'DoS GoldenEye', 8: 'DDoS'}\n"
     ]
    }
   ],
   "source": [
    "label_list = {'BENIGN': 0,\n",
    "              'PortScan': 1,\n",
    "                'Web': 2,\n",
    "                'SSH-Patator': 3,\n",
    "                'FTP-Patator': 4,\n",
    "                'Bot': 5,\n",
    "                'DoS Hulk': 6,\n",
    "                'DoS GoldenEye': 7,\n",
    "                'DDoS': 8}\n",
    "\n",
    "label_index = {}\n",
    "dict_label = {}\n",
    "for key in label_list.keys():\n",
    "    dict_label[label_list[key]] = key\n",
    "    label_index[key] = []\n",
    "print(label_index)\n",
    "print(dict_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1601232\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"CICdata.csv\"\n",
    "labels = {}\n",
    "df = pd.read_csv(data_dir)\n",
    "print(df.shape[0])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(df.shape[0]):\n",
    "    label_numb = df.iloc[i,-1]\n",
    "    label_index[dict_label[label_numb]].append(i) \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_index = []\n",
    "# test_index = []\n",
    "# for key in label_index.keys():\n",
    "#     key_index = np.array(label_index[key])\n",
    "#     data_num = key_index.shape[0]\n",
    "#     if data_num > 100000:\n",
    "#         data_num = 100000\n",
    "#     train_num = data_num*0.9    \n",
    "#     result = np.random.choice(key_index, size=int(train_num), replace=False).tolist()\n",
    "#     train_index += result\n",
    "#     test_index += [x for x in key_index.tolist() if x not in result]\n",
    "\n",
    "# train_data = df.iloc[train_index,:]\n",
    "# test_data = df.iloc[test_index,:]\n",
    "# train_data.to_csv('train_data.csv',index=False)\n",
    "# test_data.to_csv('test_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900\n"
     ]
    }
   ],
   "source": [
    "index = []\n",
    "for key in label_index.keys():\n",
    "    key_index = np.array(label_index[key])\n",
    "    result = np.random.choice(key_index, size=100, replace=False)\n",
    "    index += result.tolist()\n",
    "print(len(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 60)\n"
     ]
    }
   ],
   "source": [
    "select_data = df.iloc[index,:]\n",
    "print(select_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# select_data.to_csv('select_data2.csv', index=False)\n",
    "ids_data = NIDS_dataset('select_data.csv')\n",
    "data = torch.tensor(ids_data.items).to(torch.float32)\n",
    "label = torch.tensor(ids_data.label)\n",
    "pred = torch.max(model(data),1)[1]\n",
    "correct = (pred == label).sum()\n",
    "\n",
    "num = pred.shape[0]\n",
    "print(correct/num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7])\n"
     ]
    }
   ],
   "source": [
    "a = torch.nonzero(pred == label)\n",
    "for t in a:\n",
    "    print(t)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(875, 60)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_index = []\n",
    "for i in range(data.shape[0]):\n",
    "    sample = data[i].reshape(1,-1)\n",
    "    sample_label = label[i]\n",
    "    pred = torch.max(model(sample),1)[1]\n",
    "    if sample_label == pred:\n",
    "        correct_index.append(i)\n",
    "\n",
    "data_dir = \"select_data.csv\"\n",
    "df = pd.read_csv(data_dir)\n",
    "df = df.iloc[correct_index,:]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('select_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_data = NIDS_dataset('select_data.csv')\n",
    "data = torch.tensor(ids_data.items).to(torch.float32)\n",
    "label = torch.tensor(ids_data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNN_NIDS(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=59, out_features=4096, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Linear(in_features=4096, out_features=512, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (4): Linear(in_features=512, out_features=9, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=DNN_NIDS()\n",
    "model.load_state_dict(torch.load('CIC_model2.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2400)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred = torch.max(model(data),1)[1]\n",
    "correct = (pred == label).sum()\n",
    "num = pred.shape[0]\n",
    "print(correct/num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deepview降维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class deepView:\n",
    "    def __init__(self, pred_fn, classes, max_samples, batch_size, data_shape, n=5, \n",
    "\t\t\t\t lam=0.65, resolution=100, cmap='tab10', interactive=True, verbose=True,\n",
    "\t\t\t\t title='CICIDS2017', data_viz=None, mapper=None, inv_mapper=None, **kwargs):\n",
    "        \"\"\" \n",
    "         pred_fn: 该函数就是调用分类模型，输入数据，输出分类预测概率\n",
    "         classes: 所有类别名\n",
    "         max_samples: 可视化保留的最大样本数据，\n",
    "                     如果通过 \"add_samples\"函数传入的数据样本数超过此限制\n",
    "                     则会先删除最老的样本。\n",
    "         n: int型 计算两个样本距离用到的插值次数\n",
    "\t\t lam: 将欧几里得度量与基于分类的判别距离进行加权的系数\n",
    "        \n",
    "        \"\"\"\n",
    "        self.model = pred_fn\n",
    "        self.classes = classes\n",
    "        self.n_classes = len(classes)\n",
    "        self.max_samples = max_samples\n",
    "        self.batch_size = batch_size\n",
    "        self.data_shape = data_shape\n",
    "        self.n = n\n",
    "        self.lam = lam\n",
    "        self.resolution = resolution\n",
    "        self.cmap = plt.get_cmap(cmap)\n",
    "        self.discr_distances = np.array([])\n",
    "        self.eucl_distances = np.array([])\n",
    "        self.samples = np.empty([0, data_shape])\n",
    "        self.embedded = np.empty([0, 2])\n",
    "        self.y_true = np.array([])\n",
    "        self.y_pred = np.array([])\n",
    "        self.classifier_view = np.array([])\n",
    "        self.verbose = verbose\n",
    "        self.interactive = interactive\n",
    "        self.title = title\n",
    "        self.data_viz = data_viz\n",
    "        self._init_mappers(mapper, inv_mapper, kwargs)\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def distances(self):\n",
    "        '''\n",
    "        Combines euclidian with discriminative fisher distances.\n",
    "        Here the two distance measures are weighted with lambda\n",
    "        to emphasise structural properties (lambda > 0.5) or\n",
    "        to emphasise prediction properties (lambda < 0.5).\n",
    "        '''\n",
    "        eucl_scale = 1. / self.eucl_distances.max()\n",
    "        fisher_scale = 1. / self.discr_distances.max()\n",
    "        eucl = self.eucl_distances * eucl_scale * self.lam\n",
    "        fisher = self.discr_distances * fisher_scale * (1.-self.lam)\n",
    "        stacked = np.dstack((fisher, eucl))\n",
    "        return stacked.sum(-1)\n",
    "\n",
    "    @property\n",
    "    def num_samples(self):\n",
    "        '''\n",
    "        Returns the number of samples in DeepView.\n",
    "        '''\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def reset(self):\n",
    "        '''\n",
    "        Resets the state of DeepView to the point of initialization.\n",
    "        '''\n",
    "        self.discr_distances = np.array([])\n",
    "        self.eucl_distances = np.array([])\n",
    "        self.samples = np.empty([0, self.data_shape])\n",
    "        self.embedded = np.empty([0, 2])\n",
    "        self.y_true = np.array([])\n",
    "        self.y_pred = np.array([])\n",
    "        self.classifier_view = np.array([])\n",
    "\n",
    "    def close(self):\n",
    "        '''\n",
    "        Closes the matplotlib window, terminates DeepView.\n",
    "        '''\n",
    "        plt.close()\n",
    "\n",
    "    def set_lambda(self, lam):\n",
    "        '''\n",
    "        Sets a new lambda and recomputes the embeddings and\n",
    "        decision boundary grid.\n",
    "        '''\n",
    "        if self.lam == lam:\n",
    "            return\n",
    "        self.lam = lam\n",
    "        self.update_mappings()\n",
    "    \n",
    "    def _init_mappers(self, mapper, inv_mapper, kwargs):\n",
    "        if mapper is not None:\n",
    "            self.mapper = mapper\n",
    "        else:\n",
    "            self.mapper = init_umap(kwargs)\n",
    "        if inv_mapper is not None:\n",
    "            self.inverse = inv_mapper\n",
    "        else:\n",
    "            self.inverse = init_inv_umap(kwargs)\n",
    "\n",
    "    def _get_plot_measures(self):\n",
    "        '''\n",
    "        Computes the axis limits of the main plot by using\n",
    "        min/max values of the 2D sample embedding and adding 10%\n",
    "        on either side.\n",
    "        '''\n",
    "        ebd_min = np.min(self.embedded, axis=0)\n",
    "        ebd_max = np.max(self.embedded, axis=0)\n",
    "        ebd_extent = ebd_max - ebd_min\n",
    "\n",
    "        # get extent of embedding\n",
    "        x_min, y_min = ebd_min - 0.1 * ebd_extent\n",
    "        x_max, y_max = ebd_max + 0.1 * ebd_extent\n",
    "        return x_min, y_min, x_max, y_max\n",
    "\n",
    "    def _predict_batches(self, x):\n",
    "        '''\n",
    "        Predicts an array of samples batchwise.\n",
    "        '''\n",
    "        n_inputs = len(x)\n",
    "        preds = np.zeros([n_inputs, self.n_classes])\n",
    "\n",
    "        for i in range(0, n_inputs, self.batch_size):\n",
    "            n_preds = min(i + self.batch_size, n_inputs)\n",
    "            batch = x[i:n_preds]\n",
    "            preds[i:n_preds] = np.array(self.model(batch))\n",
    "\n",
    "        return preds\n",
    "\n",
    "\n",
    "    def add_samples(self, samples, labels):\n",
    "        '''\n",
    "        Adds samples points to the visualization.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        samples : array-like\n",
    "            List of new sample points [n_samples, *data_shape]\n",
    "        labels : array-like\n",
    "            List of labels for the sample points [n_samples, 1]\n",
    "        '''\n",
    "        # get predictions for the new samples\n",
    "        Y_probs = self._predict_batches(samples)\n",
    "        Y_preds = Y_probs.argmax(axis=1)\n",
    "        # add new values to the DeepView lists\n",
    "        self.queue_samples(samples, labels, Y_preds)\n",
    "\n",
    "        # calculate new distances\n",
    "        new_discr, new_eucl = calculate_fisher(self.model, samples, self.samples, \n",
    "            self.n, self.batch_size, self.n_classes, self.verbose)\n",
    "        # add new distances\n",
    "        self.discr_distances = self.update_matrix(self.discr_distances, new_discr)\n",
    "        self.eucl_distances = self.update_matrix(self.eucl_distances, new_eucl)\n",
    "\n",
    "        # update mappings\n",
    "        self.update_mappings()\n",
    "    \n",
    "\n",
    "    def queue_samples(self, samples, labels, preds):\n",
    "        '''\n",
    "        Adds samples labels and predictions to the according lists of\n",
    "        this deepview object. Old values will be discarded, when there are \n",
    "        more then max_samples.\n",
    "        '''\n",
    "        # add new samples and remove depricated samples\n",
    "        self.samples = np.concatenate((samples, self.samples))[:self.max_samples]\n",
    "        self.y_pred = np.concatenate((preds, self.y_pred))[:self.max_samples]\n",
    "        self.y_true = np.concatenate((labels, self.y_true))[:self.max_samples]\n",
    "\n",
    "    def update_matrix(self, old_matrix, new_values):\n",
    "        '''\n",
    "        When new distance values are calculated this merges old \n",
    "        and new distances into the same matrix.\n",
    "        '''\n",
    "        n_new = new_values.shape[0]\n",
    "        n_keep = self.max_samples - n_new\n",
    "        to_triu = np.triu(old_matrix, k=1)\n",
    "        new_mat = np.zeros([self.num_samples, self.num_samples])\n",
    "        new_mat[n_new:,n_new:] = to_triu[:n_keep,:n_keep]\n",
    "        new_mat[:n_new] = new_values\n",
    "        return new_mat + new_mat.transpose()\n",
    "\n",
    "    def update_mappings(self):\n",
    "        if self.verbose:\n",
    "            print('Embedding samples ...')\n",
    "\n",
    "        self.mapper.fit(self.distances)\n",
    "        self.embedded = self.mapper.transform(self.distances)\n",
    "        self.inverse.fit(self.embedded, self.samples)\n",
    "        self.classifier_view = self.compute_grid()\n",
    "    \n",
    "\n",
    "    def compute_grid(self):\n",
    "        '''\n",
    "        Computes the visualisation of the decision boundaries.\n",
    "        '''\n",
    "        if self.verbose:\n",
    "            print('Computing decision regions ...')\n",
    "        # get extent of embedding\n",
    "        x_min, y_min, x_max, y_max = self._get_plot_measures()\n",
    "        # create grid\n",
    "        xs = np.linspace(x_min, x_max, self.resolution)\n",
    "        ys = np.linspace(y_min, y_max, self.resolution)\n",
    "        self.grid = np.array(np.meshgrid(xs, ys))\n",
    "        grid = np.swapaxes(self.grid.reshape(self.grid.shape[0],-1),0,1)\n",
    "\n",
    "        # map gridmpoint to images\n",
    "        grid_samples = self.inverse(grid)\n",
    "\n",
    "        mesh_preds = self._predict_batches(grid_samples)\n",
    "        mesh_preds = mesh_preds + 1e-8\n",
    "\n",
    "        self.mesh_classes = mesh_preds.argmax(axis=1)\n",
    "        mesh_max_class = max(self.mesh_classes)\n",
    "\n",
    "        # get color of gridpoints\n",
    "        color = self.cmap(self.mesh_classes/mesh_max_class)\n",
    "        # scale colors by certainty\n",
    "        h = -(mesh_preds*np.log(mesh_preds)).sum(axis=1)/np.log(self.n_classes)\n",
    "        h = (h/h.max()).reshape(-1, 1)\n",
    "        # adjust brightness\n",
    "        h = np.clip(h*1.2, 0, 1)\n",
    "        color = color[:,0:3]\n",
    "        color = (1-h)*(0.5*color) + h*np.ones(color.shape, dtype=np.uint8)\n",
    "        decision_view = color.reshape(self.resolution, self.resolution, 3)\n",
    "        return decision_view\n",
    "    \n",
    "\n",
    "    def show_sample(self, event):\n",
    "        '''\n",
    "        Invoked when the user clicks on the plot. Determines the\n",
    "        embedded or synthesised sample at the click location and \n",
    "        passes it to the data_viz method, together with the prediction, \n",
    "        if present a groun truth label and the 2D click location.\n",
    "        '''\n",
    "\n",
    "        # when there is an artist attribute, a \n",
    "        # concrete sample was clicked, otherwise\n",
    "        # show the according synthesised image\n",
    "        if hasattr(event, 'artist'):\n",
    "            artist = event.artist\n",
    "            ind = event.ind\n",
    "            xs, ys = artist.get_data()\n",
    "            point = [xs[ind][0], ys[ind][0]]\n",
    "            sample, p, t = self.get_artist_sample(point)\n",
    "            title = '%s <-> %s' if p != t else '%s --- %s'\n",
    "            title = title % (self.classes[p], self.classes[t])\n",
    "            self.disable_synth = True\n",
    "        elif not self.disable_synth:\n",
    "            # workaraound: inverse embedding needs more points\n",
    "            # otherwise it doens't work --> [point]*5\n",
    "            point = np.array([[ event.xdata , event.ydata ]]*5)\n",
    "\n",
    "            # if the outside of the plot was clicked, points are None\n",
    "            if None in point[0]:\n",
    "                return\n",
    "\n",
    "            sample = self.inverse(point)[0]\n",
    "            sample += abs(sample.min())\n",
    "            sample /= sample.max()\n",
    "            title = 'Synthesised at [%.1f, %.1f]' % tuple(point[0])\n",
    "            p, t = self.get_mesh_prediction_at(*point[0]), None\n",
    "        else:\n",
    "            self.disable_synth = False\n",
    "            return\n",
    "\n",
    "        is_image = self.is_image(sample)\n",
    "        rank_perm = np.roll(range(len(sample.shape)), -1)\n",
    "        sample_T = sample.transpose(rank_perm)\n",
    "        is_transformed_image = self.is_image(sample_T)\n",
    "\n",
    "        if self.data_viz is not None:\n",
    "            self.data_viz(sample, point, p, t)\n",
    "            return\n",
    "        # try to show the image, if the shape allows it\n",
    "        elif is_image:\n",
    "            img = sample - sample.min()\n",
    "        elif is_transformed_image:\n",
    "            img = sample_T - sample_T.min()\n",
    "        else:\n",
    "            warnings.warn(\"Data visualization not possible, as the data points have\"\n",
    "                \"no image shape. Pass a function in the data_viz argument,\"\n",
    "                \"to enable custom data visualization.\")\n",
    "            return\n",
    "\n",
    "        f, a = plt.subplots(1, 1)\n",
    "        a.imshow(img / img.max())\n",
    "        a.set_title(title)\n",
    "          \n",
    "\n",
    "\n",
    "    def _init_plots(self):\n",
    "        '''\n",
    "        Initialises matplotlib artists and plots.\n",
    "        '''\n",
    "        if self.interactive:\n",
    "            plt.ion()\n",
    "        self.fig, self.ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "        # self.ax.set_title(self.title)\n",
    "        self.desc = self.fig.text(0.5, 0.02, '', fontsize=8, ha='center')\n",
    "        self.cls_plot = self.ax.imshow(np.zeros([5, 5, 3]), \n",
    "            interpolation='gaussian', zorder=0, vmin=0, vmax=1)\n",
    "\n",
    "        self.sample_plots = []\n",
    "\n",
    "        for c in range(self.n_classes):\n",
    "            color = self.cmap(c/(self.n_classes-1))\n",
    "            plot = self.ax.plot([], [], 'o', label=self.classes[c], \n",
    "                color=color, zorder=2, picker=mpl.rcParams['lines.markersize'])\n",
    "            self.sample_plots.append(plot[0])\n",
    "\n",
    "        for c in range(self.n_classes):\n",
    "            color = self.cmap(c/(self.n_classes-1))\n",
    "            plot = self.ax.plot([], [], 'o', markeredgecolor=color, \n",
    "                fillstyle='none', ms=12, mew=2.5, zorder=1)\n",
    "            self.sample_plots.append(plot[0])\n",
    "\n",
    "        # set the mouse-event listeners\n",
    "        self.fig.canvas.mpl_connect('pick_event', self.show_sample)\n",
    "        self.fig.canvas.mpl_connect('button_press_event', self.show_sample)\n",
    "        self.disable_synth = False\n",
    "        self.ax.legend()\n",
    "\n",
    "    def show(self):\n",
    "        '''\n",
    "        Shows the current plot.\n",
    "        '''\n",
    "        if not hasattr(self, 'fig'):\n",
    "            self._init_plots()\n",
    "\n",
    "        x_min, y_min, x_max, y_max = self._get_plot_measures()\n",
    "\n",
    "        self.cls_plot.set_data(self.classifier_view)\n",
    "        self.cls_plot.set_extent((x_min, x_max, y_max, y_min))\n",
    "        self.ax.set_xlim((x_min, x_max))\n",
    "        self.ax.set_ylim((y_min, y_max))\n",
    "\n",
    "        params_str = 'batch size: %d - n: %d - $\\lambda$: %.2f - res: %d'\n",
    "        desc = params_str % (self.batch_size, self.n, self.lam, self.resolution)\n",
    "        self.desc.set_text(desc)\n",
    "\n",
    "        for c in range(self.n_classes):\n",
    "            data = self.embedded[self.y_true==c]\n",
    "            print(data.shape)\n",
    "            self.sample_plots[c].set_data(data.transpose())\n",
    "\n",
    "        for c in range(self.n_classes):\n",
    "            data = self.embedded[np.logical_and(self.y_pred==c, self.y_true!=c)]\n",
    "            self.sample_plots[self.n_classes+c].set_data(data.transpose())\n",
    "\n",
    "        if os.name == 'posix':\n",
    "            self.fig.canvas.manager.window.raise_()\n",
    "            \n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.canvas.flush_events()\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model=DNN_NIDS()\n",
    "torch_model.load_state_dict(torch.load('CIC_model2.pth'))\n",
    "torch_model.eval()\n",
    "ids_dataset = NIDS_dataset('select_data.csv')\n",
    "softmax = torch.nn.Softmax(dim=-1)\n",
    "def pred_wrapper(x):\n",
    "    with torch.no_grad():\n",
    "        x = np.array(x, dtype=np.float32)\n",
    "        tensor = torch.from_numpy(x)\n",
    "        logits = torch_model(tensor)\n",
    "        probabilities = softmax(logits).cpu().numpy()\n",
    "    return probabilities\n",
    "\n",
    "def visualization(image, point2d, pred, label=None, title=None):\n",
    "    f, a = plt.subplots()\n",
    "    a.set_title(title)\n",
    "    a.imshow(image.transpose([1, 2, 0]))\n",
    "\n",
    "\n",
    "classes =  ('BENIGN',\n",
    "            'PortScan',\n",
    "            'Web',\n",
    "            'SSH-Patator',\n",
    "            'FTP-Patator',\n",
    "            'Bot',\n",
    "            'DoS Hulk',\n",
    "            'DoS GoldenEye',\n",
    "            'DDoS',\n",
    "            )\n",
    "batch_size = 512\n",
    "max_samples = 1000\n",
    "data_shape = (59)\n",
    "lam = 0\n",
    "title = 'Origin Samples'\n",
    "\n",
    "deepview = deepView(pred_wrapper, classes, max_samples, batch_size, \n",
    "                    data_shape, lam=lam, title=title)\n",
    "\n",
    "\n",
    "\n",
    "adv_datas = np.load('adv_data/adv_data.npy')\n",
    "adv_labels = np.array([1]*adv_datas.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance calculation 20.00 %\n",
      "Distance calculation 40.00 %\n",
      "Distance calculation 60.00 %\n",
      "Distance calculation 80.00 %\n",
      "Distance calculation 100.00 %\n",
      "Embedding samples ...\n",
      "Computing decision regions ...\n"
     ]
    }
   ],
   "source": [
    "# X = np.vstack((ids_dataset.items,adv_datas))\n",
    "# Y = np.concatenate((ids_dataset.label,adv_labels))\n",
    "# X = ids_dataset.items\n",
    "X = adv_datas\n",
    "Y = ids_dataset.label\n",
    "deepview.add_samples(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-385a92160010>:306: MatplotlibDeprecationWarning: Setting the line's pick radius via set_picker is deprecated since 3.3 and will be removed two minor releases later; use set_pickradius instead.\n",
      "  plot = self.ax.plot([], [], 'o', label=self.classes[c],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92, 2)\n",
      "(100, 2)\n",
      "(91, 2)\n",
      "(100, 2)\n",
      "(100, 2)\n",
      "(99, 2)\n",
      "(96, 2)\n",
      "(100, 2)\n",
      "(97, 2)\n"
     ]
    }
   ],
   "source": [
    "deepview.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "print(len(deepview.sample_plots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "919\n"
     ]
    }
   ],
   "source": [
    "print(len(deepview.y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
